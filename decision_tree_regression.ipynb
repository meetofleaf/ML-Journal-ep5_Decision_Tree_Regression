{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Default Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"petrol_consumption.csv\")\n",
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,0:2].values     # Petrol tax, Average income\n",
    "y = dataset.iloc[:,-1].values      # Petrol consumption\n",
    "#plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We train our model DecisionTreeRegressor class and fit method\n",
    "regressor = DecisionTreeRegressor(random_state=0, max_depth=5)  # random_state adds a dash of randomness to how the decision tree is built, but it doesn't significantly affect the final predictions (variable value and randomness are inversely proportional)\n",
    "                                                                # max_depth simply decides how tall the tree will be generated. The number of levels are excluding the parent level/node\n",
    "                                                                # For more parameters explore: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "regressor.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a simple function to predict the dependent variable for code reusability\n",
    "def predict(model, inputs):\n",
    "    return model.predict(inputs)\n",
    "\n",
    "predict(regressor, [[15, 5500]])    # petrol_tax, average_income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code snippet visualizes the decision tree showing the tree's branches and nodes/leaves\n",
    "\n",
    "plt.figure(figsize=(25,18))         # Define image size\n",
    "plot_tree(regressor, fontsize=9)    # Plot the tree with plot_tree method and provide the model as input and set font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the model is trained on just 2 variables (1 dependent and 1 independent), then we'll be able to build a 2-D chart with the below given code snippet\n",
    "\n",
    "'''\n",
    "X_grid = np.arange(min(X), max(X), 0.1)\n",
    "y_grid = X_grid.reshape((len(X_grid), 1))\n",
    "plt.scatter(X,y, color='red')\n",
    "plt.plot(X_grid, regressor.predict(X_grid.reshape(-1, 1)), color='blue')\n",
    "plt.xlabel('Average Income')\n",
    "plt.ylabel('Petrol Consumption')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing 3 variable model on 2D chart using one average_income value\n",
    "petrol_tax_range = np.arange(min(X[:, 0]), max(X[:, 0]), 0.1)  # range of petrol tax values\n",
    "average_income = 5500  # constant average income for visualization\n",
    "\n",
    "# Make predictions for each petrol tax value in the range\n",
    "predictions = regressor.predict(np.column_stack((petrol_tax_range, np.full_like(petrol_tax_range, average_income))))\n",
    "\n",
    "# Plot the original data points\n",
    "plt.scatter(X[:, 0], y, color='red', label='Original data')\n",
    "\n",
    "# Plot the predictions against petrol tax\n",
    "plt.plot(petrol_tax_range, predictions, color='blue', label='Decision Tree Regression')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title('Decision Tree Regression')\n",
    "plt.xlabel('Petrol Tax')\n",
    "plt.ylabel('Petrol Consumption')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
